# ğŸ§  Projeto: ElaboraÃ§Ã£o de uma Rede Neural para o Problema do XOR

Este projeto tem como objetivo a **implementaÃ§Ã£o e exploraÃ§Ã£o de Redes Neurais Artificiais** aplicadas ao problema clÃ¡ssico do **XOR (Exclusive OR)**.  
O trabalho contempla desde a geraÃ§Ã£o de dados sintÃ©ticos, visualizaÃ§Ã£o e preparaÃ§Ã£o atÃ© a modelagem, treinamento, avaliaÃ§Ã£o e experimentaÃ§Ã£o de diferentes arquiteturas de redes neurais *feedforward* (MLPs â€” *Multi-Layer Perceptrons*).

---

## ğŸ“‘ SumÃ¡rio

- [DescriÃ§Ã£o do Problema](#-descriÃ§Ã£o-do-problema)
- [Objetivos do Projeto](#-objetivos-do-projeto)
- [Arquitetura e Modelagem](#-arquitetura-e-modelagem)
- [Resultados Obtidos](#-resultados-obtidos)
- [VisualizaÃ§Ãµes e SaÃ­das](#-visualizaÃ§Ãµes-e-saÃ­das)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#-instalaÃ§Ã£o-e-execuÃ§Ã£o)
- [Requisitos](#-requisitos)
- [PrÃ³ximos Passos](#-prÃ³ximos-passos)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ“Œ DescriÃ§Ã£o do Problema

O **problema do XOR** Ã© um desafio clÃ¡ssico em InteligÃªncia Artificial que demonstra a limitaÃ§Ã£o de modelos lineares. Ele nÃ£o pode ser resolvido por um Ãºnico perceptron, exigindo uma rede com **camadas intermediÃ¡rias** (*hidden layers*) para aprender a fronteira de decisÃ£o nÃ£o linear.  

A soluÃ§Ã£o aqui apresentada utiliza **dados sintÃ©ticos** que simulam distribuiÃ§Ãµes em torno de quatro centros correspondentes Ã s combinaÃ§Ãµes do XOR.

---

## ğŸ¯ Objetivos do Projeto

- Implementar modelos de redes neurais do tipo MLP para classificar o problema do XOR.
- Demonstrar a evoluÃ§Ã£o do treinamento por meio de mÃ©tricas e visualizaÃ§Ãµes.
- Avaliar o impacto de **diferentes arquiteturas** e **hiperparÃ¢metros**.
- Explorar as melhores combinaÃ§Ãµes para **acurÃ¡cia, simplicidade e eficiÃªncia**.

---

## ğŸ—ï¸ Arquitetura e Modelagem

1. **MLP Baseline (MLP1)**  
   - Camada oculta com 8 neurÃ´nios (`tanh`).  
   - Camada oculta adicional com 4 neurÃ´nios (`tanh`).  
   - Camada de saÃ­da com 1 neurÃ´nio (`sigmoid`).  

2. **MLP ExploratÃ³ria (MLP2)**  
   - VariaÃ§Ã£o da quantidade de camadas e neurÃ´nios.  
   - ExploraÃ§Ã£o de diferentes hiperparÃ¢metros.  
   - ComparaÃ§Ã£o de otimizadores (`Adam`, `SGD`).  

3. **Treinamento e AvaliaÃ§Ã£o**  
   - FunÃ§Ã£o de perda: `binary_crossentropy`.  
   - MÃ©trica: `binary_accuracy`.  
   - AvaliaÃ§Ã£o de desempenho por **acurÃ¡cia final** e curvas de treinamento.

---

## ğŸ“Š Resultados Obtidos

- O modelo baseline (MLP1) alcanÃ§ou **acurÃ¡cia superior a 95%**, com convergÃªncia estÃ¡vel.  
- ConfiguraÃ§Ãµes mais profundas (MLP2) atingiram **100% de acurÃ¡cia** em diversas combinaÃ§Ãµes.  
- A visualizaÃ§Ã£o mostrou claramente a capacidade da rede em separar classes nÃ£o linearmente separÃ¡veis.  

Exemplo de saÃ­da:

Entrada: [0 0] â†’ Esperado: 0 | Previsto: 0 (0.0123)
Entrada: [0 1] â†’ Esperado: 1 | Previsto: 1 (0.9987)
Entrada: [1 0] â†’ Esperado: 1 | Previsto: 1 (0.9971)
Entrada: [1 1] â†’ Esperado: 0 | Previsto: 0 (0.0089)

---

## ğŸ“ˆ VisualizaÃ§Ãµes e SaÃ­das

### ğŸ”¹ DistribuiÃ§Ã£o dos Dados (XOR)

<p align="center">
  <img src="images/xor_dataset.png" alt="DistribuiÃ§Ã£o dos dados XOR" width="500"/>
</p>

---

### ğŸ”¹ Curva de Treinamento â€” Loss

<p align="center">
  <img src="images/model_loss.png" alt="Curva de Loss" width="500"/>
</p>

---

### ğŸ”¹ Curva de Treinamento â€” Accuracy

<p align="center">
  <img src="images/model_accuracy.png" alt="Curva de Accuracy" width="500"/>
</p>

---

### ğŸ”¹ Exemplo de PrevisÃµes do Modelo

<p align="center">
  <img src="images/model_predictions.png" alt="Exemplo de previsÃµes do modelo" width="500"/>
</p>

> As imagens acima podem ser geradas a partir do notebook e salvas na pasta `images/` para visualizaÃ§Ã£o no GitHub.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.9+**
- [NumPy](https://numpy.org/)
- [Pandas](https://pandas.pydata.org/)
- [Matplotlib](https://matplotlib.org/)
- [TensorFlow / Keras](https://www.tensorflow.org/)

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. Clone este repositÃ³rio:
   ```bash
   git clone https://github.com/<seu-usuario>/<seu-repositorio>.git
   cd <seu-repositorio>

   python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt

jupyter notebook Projeto_ElaboraÃ§Ã£o_de_uma_Rede_Neural.ipynb

numpy==1.26.4
pandas==2.2.2
matplotlib==3.9.0
tensorflow==2.16.1
ReferÃªncias

Keras Documentation

TensorFlow Guides

Deep Learning Book - Ian Goodfellow


